{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8deb94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [17, 6]\n",
    "from IPython.display import Audio\n",
    "from ipywidgets import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa27858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204833f",
   "metadata": {},
   "source": [
    "### This just works for reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_conv1d(signal, kernel):\n",
    "    padded_kernel = F.pad(kernel, (0, signal.shape[-1] - kernel.shape[-1]))\n",
    "    \n",
    "    f_signal = fft.rfft(signal)\n",
    "    f_kernel = fft.rfft(padded_kernel)\n",
    "    \n",
    "    f_kernel = torch.conj(f_kernel)\n",
    "    \n",
    "    f_conv = f_signal * f_kernel\n",
    "    f_conv = fft.irfft(f_conv)\n",
    "    f_conv = f_conv[..., :signal.shape[-1] - kernel.shape[-1] + 1]\n",
    "    \n",
    "    return f_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ba200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, C, L\n",
    "signal = torch.randn(10, 1, 1000)\n",
    "# OC, IC, L\n",
    "kernel = torch.randn(1, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, OC, OL\n",
    "conv = F.conv1d(signal, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, OC, OL\n",
    "f_conv = fft_conv1d(signal, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(conv, f_conv, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194ba3b",
   "metadata": {},
   "source": [
    "### Batched sequence kernel fft_conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, S, C, L\n",
    "signal = torch.randn(5, 10, 1, 1000)\n",
    "# N, S, C, B\n",
    "bands = torch.randn(5, 10, 1, 51)\n",
    "kernel = fft.fftshift(fft.irfft(bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge batch, sequence, channel dimensions\n",
    "signal_ = signal.reshape(signal.shape[0] * signal.shape[1] * signal.shape[2], signal.shape[3])\n",
    "kernel_ = kernel.reshape(kernel.shape[0] * kernel.shape[1] * kernel.shape[2], kernel.shape[3])\n",
    "# add batch dim\n",
    "signal_ = signal_.unsqueeze(0)\n",
    "# add in channel dim\n",
    "kernel_ = kernel_.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc1090",
   "metadata": {},
   "source": [
    "### Looping over kernels is equivalent to group convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = F.conv1d(signal_, kernel_, groups=kernel_.shape[0])\n",
    "conv = conv.reshape(signal.shape[0], signal.shape[1], signal.shape[2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01aa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_signal = signal.reshape(signal.shape[0] * signal.shape[1], 1, signal.shape[2], signal.shape[3])\n",
    "l_kernel = kernel.reshape(kernel.shape[0] * kernel.shape[1], 1, kernel.shape[2], kernel.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d35ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_conv = []\n",
    "for s, k in zip(l_signal, l_kernel):\n",
    "    l_conv.append(F.conv1d(s, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dd43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_conv = torch.cat(l_conv, dim=1)\n",
    "l_conv = l_conv.reshape(signal.shape[0], signal.shape[1], signal.shape[2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ae8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(conv, l_conv, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052ed47",
   "metadata": {},
   "source": [
    "### And this is batched sequence convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc013393",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_conv = fft_conv1d(signal_, kernel_.transpose(0, 1))\n",
    "f_conv = f_conv.reshape(signal.shape[0], signal.shape[1], signal.shape[2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(conv, f_conv, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50308aff",
   "metadata": {},
   "source": [
    "### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc966f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_fft_conv1d(signal, kernel):\n",
    "    # merge batch, sequence, channel dimensions\n",
    "    signal_ = signal.reshape(signal.shape[0] * signal.shape[1] * signal.shape[2], signal.shape[3])\n",
    "    kernel_ = kernel.reshape(kernel.shape[0] * kernel.shape[1] * kernel.shape[2], kernel.shape[3])\n",
    "    # add batch dim\n",
    "    signal_ = signal_.unsqueeze(0)\n",
    "    # add out channel dim\n",
    "    kernel_ = kernel_.unsqueeze(0)\n",
    "    \n",
    "    f_conv = fft_conv1d(signal_, kernel_)\n",
    "    f_conv = f_conv.reshape(signal.shape[0], signal.shape[1], signal.shape[2], -1)\n",
    "    \n",
    "    return f_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_conv = grouped_fft_conv1d(signal, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(conv, f_conv, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d427e",
   "metadata": {},
   "source": [
    "### Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_size = 480\n",
    "seq_len = 10\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand(batch_size, 1, seq_len * hop_size + hop_size) * 2.0 - 1.0\n",
    "framed_noise = noise.unfold(-1, hop_size * 2, hop_size).transpose(1, 2)\n",
    "print(noise.shape, framed_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8192d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
