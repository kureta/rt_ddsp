{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [17, 12]\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rt_ddsp.synths import Harmonic, OscillatorBank\n",
    "from rt_ddsp import core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ff65c",
   "metadata": {},
   "source": [
    "We generate a signal using `Harmonic`, take the FFT of it, and compare its FFT peaks with the control values. Also takes into consideration filtlering above Nyquist frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2527a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Any, Dict\n",
    "\n",
    "def get_frequency_peaks(signal: torch.Tensor,\n",
    "                        sample_rate: int,\n",
    "                        height: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    spectrum = np.abs(np.fft.rfft(signal.numpy())) / (len(signal) / 2)\n",
    "    peaks, _ = find_peaks(spectrum, height=height)\n",
    "    peak_freqs = np.fft.rfftfreq(len(signal), 1 / sample_rate)[peaks]\n",
    "    peak_amps = spectrum[peaks]\n",
    "\n",
    "    plt.plot(spectrum)\n",
    "    plt.plot(peaks, spectrum[peaks], \"x\")\n",
    "    plt.plot(np.zeros_like(spectrum), \"--\", color=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    return core.torch_float32(peak_freqs), core.torch_float32(peak_amps)\n",
    "\n",
    "\n",
    "def get_batch_frequency_peaks(signal: torch.Tensor,\n",
    "                              sample_rate: int,\n",
    "                              height: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    peak_freqs = []\n",
    "    peak_amps = []\n",
    "    for s in signal:\n",
    "        pf, pa = get_frequency_peaks(s, sample_rate, height)\n",
    "        peak_freqs.append(pf)\n",
    "        peak_amps.append(pa)\n",
    "\n",
    "    return torch.stack(peak_freqs), torch.stack(peak_amps)\n",
    "\n",
    "\n",
    "def static_sawtooth_features(fundamental_frequency: float,\n",
    "                             base_amplitude: float,\n",
    "                             n_harmonics: int = 30,\n",
    "                             n_frames: int = 1000,\n",
    "                             batch_size: int = 3) -> Dict[str, torch.Tensor]:\n",
    "    amp = torch.zeros(batch_size, n_frames, 1) + base_amplitude\n",
    "\n",
    "    harmonic_distribution = 1 / torch.arange(1, n_harmonics + 1)\n",
    "    # harmonic_distribution = torch.ones(n_harmonics)  # impulse features\n",
    "    harmonic_distribution = harmonic_distribution.view(1, 1, n_harmonics).repeat(batch_size, n_frames, 1)\n",
    "\n",
    "    f0_hz = torch.zeros(batch_size, n_frames, 1) + fundamental_frequency\n",
    "\n",
    "    return {\n",
    "        'amplitudes': amp,\n",
    "        'harmonic_distribution': harmonic_distribution,\n",
    "        'f0_hz': f0_hz\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_harmonics=10\n",
    "batch_size=1\n",
    "f0=220.\n",
    "amp=0.6\n",
    "\n",
    "n_frames = 500\n",
    "\n",
    "harmonic_synth = Harmonic(16000*2, 16000)\n",
    "sample_rate = harmonic_synth.sample_rate\n",
    "controls = static_sawtooth_features(f0, amp, n_harmonics, n_frames, batch_size)\n",
    "signal = harmonic_synth(**controls)\n",
    "modified_controls = harmonic_synth.get_controls(**controls)\n",
    "\n",
    "shit_mask = modified_controls['harmonic_distribution'][0, 0] > 0.\n",
    "height = (modified_controls['harmonic_distribution'][:, :, shit_mask] * modified_controls[\n",
    "    'amplitudes']).numpy().min() * 0.99\n",
    "peak_freqs, peak_amps = get_batch_frequency_peaks(\n",
    "    signal, sample_rate, height)\n",
    "\n",
    "expected_peak_freqs = f0 * torch.arange(1, n_harmonics + 1)\n",
    "expected_peak_freqs = expected_peak_freqs.repeat(batch_size, 1)\n",
    "\n",
    "dist_amps = modified_controls['harmonic_distribution'][:, 0, :]\n",
    "base_amps = modified_controls['amplitudes'][:, 0, :]\n",
    "expected_peak_amps = (dist_amps * base_amps)\n",
    "\n",
    "# filter above nyquist\n",
    "# TODO: currently we are assuming the whole batch has the same f0, harmonic, and amp values\n",
    "#       otherwise peak_freqs and expected_peak_frames would have different sizes\n",
    "#       later handle this by zero padding the smaller one or something like that\n",
    "mask = expected_peak_freqs[0].lt(sample_rate / 2)\n",
    "expected_peak_amps = expected_peak_amps[:, mask]\n",
    "expected_peak_freqs = expected_peak_freqs[:, mask]\n",
    "\n",
    "np.testing.assert_array_almost_equal(peak_freqs, expected_peak_freqs, decimal=5)\n",
    "np.testing.assert_array_almost_equal(peak_amps, expected_peak_amps, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(signal, rate=16000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffff5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_harmonics=30\n",
    "batch_size=1\n",
    "f0=220.\n",
    "amp=0.6\n",
    "\n",
    "n_frames = 50\n",
    "\n",
    "harmonic_synth = OscillatorBank(1, 16000, n_harmonics, 512)\n",
    "sample_rate = harmonic_synth.sample_rate\n",
    "controls = static_sawtooth_features(f0, amp, n_harmonics, n_frames, batch_size)\n",
    "controls['harmonic_distribution'] /= controls['harmonic_distribution'].sum(-1, keepdim=True)\n",
    "signal = harmonic_synth(controls)\n",
    "modified_controls = controls\n",
    "\n",
    "shit_mask = modified_controls['harmonic_distribution'][0, 0] > 0.\n",
    "height = (modified_controls['harmonic_distribution'][:, :, shit_mask] * modified_controls[\n",
    "    'amplitudes']).numpy().min() * 0.99\n",
    "peak_freqs, peak_amps = get_batch_frequency_peaks(\n",
    "    signal, sample_rate, height)\n",
    "\n",
    "expected_peak_freqs = f0 * torch.arange(1, n_harmonics + 1)\n",
    "expected_peak_freqs = expected_peak_freqs.repeat(batch_size, 1)\n",
    "\n",
    "dist_amps = modified_controls['harmonic_distribution'][:, 0, :]\n",
    "base_amps = modified_controls['amplitudes'][:, 0, :]\n",
    "expected_peak_amps = (dist_amps * base_amps)\n",
    "\n",
    "# filter above nyquist\n",
    "# TODO: currently we are assuming the whole batch has the same f0, harmonic, and amp values\n",
    "#       otherwise peak_freqs and expected_peak_frames would have different sizes\n",
    "#       later handle this by zero padding the smaller one or something like that\n",
    "mask = expected_peak_freqs[0].lt(sample_rate / 2)\n",
    "expected_peak_amps = expected_peak_amps[:, mask]\n",
    "expected_peak_freqs = expected_peak_freqs[:, mask]\n",
    "\n",
    "np.testing.assert_array_almost_equal(peak_freqs, expected_peak_freqs, decimal=5)\n",
    "np.testing.assert_array_almost_equal(peak_amps, expected_peak_amps, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a125da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(signal, rate=16000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_signal = []\n",
    "harmonic_synth.last_phases[...] = 0.0\n",
    "\n",
    "for i in range(50):\n",
    "    rt_signal.append(harmonic_synth({\n",
    "        k: v[:, i, :].unsqueeze(1) for k, v in controls.items()\n",
    "    }))\n",
    "\n",
    "rt_signal = torch.cat(rt_signal, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(signal, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(rt_signal, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bec842",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(signal - rt_signal).mean(), torch.abs(signal - rt_signal).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_synth.last_phases[...] = 0.0\n",
    "signal2 = harmonic_synth(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(signal - signal2).mean(), torch.abs(signal - signal2).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b70e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
