{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2130661",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [17, 6]\n",
    "from IPython.display import Audio\n",
    "from ipywidgets import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torchcrepe\n",
    "import torch\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = Path('/home/kureta/Music/violin/Violin Samples/yee_amazing_grace#7.wav')\n",
    "file = Path('/home/kureta/Music/violin/Violin Samples/yee_amazing_grace.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a81bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 48000\n",
    "# Load audio\n",
    "audio, sr = librosa.load(file, sample_rate)\n",
    "audio = torch.from_numpy(audio.astype('float32')).unsqueeze(0)\n",
    "\n",
    "# Here we'll use a 10 millisecond hop length\n",
    "hop_length = 480\n",
    "\n",
    "# Provide a sensible frequency range for your domain (upper limit is 2006 Hz)\n",
    "# This would be a reasonable range for speech\n",
    "fmin = 190\n",
    "fmax = 2800\n",
    "\n",
    "# Select a model capacity--one of \"tiny\" or \"full\"\n",
    "model = 'full'\n",
    "\n",
    "# Choose a device to use for inference\n",
    "device = 'cuda'\n",
    "\n",
    "# Pick a batch size that doesn't cause memory errors on your gpu\n",
    "batch_size = 2048\n",
    "\n",
    "# Compute pitch using first gpu\n",
    "pitch, periodicity = torchcrepe.predict(audio,\n",
    "                           sr,\n",
    "                           hop_length,\n",
    "                           fmin,\n",
    "                           fmax,\n",
    "                           model,\n",
    "                           batch_size=batch_size,\n",
    "                           device=device,\n",
    "                           decoder=torchcrepe.decode.viterbi,\n",
    "                           return_periodicity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9049cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter silence\n",
    "periodicity = torchcrepe.threshold.Silence(-90.)(periodicity,\n",
    "                                                 audio,\n",
    "                                                 sr,\n",
    "                                                 hop_length)\n",
    "\n",
    "# We'll use a 15 millisecond window assuming a hop length of 5 milliseconds\n",
    "win_length = 3\n",
    "\n",
    "# Median filter noisy confidence value\n",
    "periodicity = torchcrepe.filter.median(periodicity, win_length)\n",
    "\n",
    "# Remove inharmonic regions\n",
    "pitch = torchcrepe.threshold.At(.21)(pitch, periodicity)\n",
    "\n",
    "# Optionally smooth pitch to remove quantization artifacts\n",
    "pitch = torchcrepe.filter.mean(pitch, win_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3280b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness = torchcrepe.loudness.a_weighted(audio, sample_rate, hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(periodicity[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loudness[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89aa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch.isnan().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8be49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "331433/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a73a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
