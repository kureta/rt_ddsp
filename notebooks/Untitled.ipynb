{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [17, 6]\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.fft as fft\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eec3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OscillatorBank(nn.Module):\n",
    "    def __init__(self, batch_size=4, sample_rate=16000, n_harmonics=100, hop_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_harmonics = n_harmonics\n",
    "        self.sample_rate = sample_rate\n",
    "        self.hop_size = hop_size\n",
    "\n",
    "        self.harmonics = nn.Parameter(\n",
    "            torch.arange(1, self.n_harmonics + 1, step=1), requires_grad=False\n",
    "        )\n",
    "        self.last_phases = nn.Parameter(\n",
    "            torch.rand(batch_size, n_harmonics) * 2. * np.pi - np.pi, requires_grad=False\n",
    "        )\n",
    "\n",
    "    def prepare_harmonics(self, f0: Tensor, harm_amps: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        # Hz (cycles per second)\n",
    "        harmonics = (\n",
    "            self.harmonics.unsqueeze(0).unsqueeze(0).repeat(f0.shape[0], f0.shape[1], 1)\n",
    "            * f0\n",
    "        )\n",
    "        # zero out above nyquist\n",
    "        mask = harmonics > self.sample_rate // 2\n",
    "        harm_amps = harm_amps.masked_fill(mask, 0.0)\n",
    "        harm_amps /= harm_amps.sum(-1, keepdim=True)\n",
    "        harmonics *= 2 * np.pi  # radians per second\n",
    "        harmonics /= self.sample_rate  # radians per sample\n",
    "        harmonics = self.rescale(harmonics)\n",
    "        return harmonics, harm_amps\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_phases(harmonics: Tensor) -> Tensor:\n",
    "        phases = torch.cumsum(harmonics, dim=1)\n",
    "        phases %= 2 * np.pi\n",
    "        return phases\n",
    "\n",
    "    def generate_signal(\n",
    "        self, harm_amps: Tensor, loudness: Tensor, phases: Tensor\n",
    "    ) -> Tensor:\n",
    "        loudness = self.rescale(loudness)\n",
    "        harm_amps = self.rescale(harm_amps)\n",
    "        signal = loudness * harm_amps * torch.sin(phases)\n",
    "        signal = torch.sum(signal, dim=2)\n",
    "        return signal\n",
    "\n",
    "    def rescale(self, x: Tensor) -> Tensor:\n",
    "        return F.interpolate(\n",
    "            x.permute(0, 2, 1),\n",
    "            scale_factor=float(self.hop_size),\n",
    "            mode='linear',\n",
    "            align_corners=False,\n",
    "        ).permute(0, 2, 1)\n",
    "\n",
    "    def forward(self, x: Dict[str, Tensor]) -> Tensor:\n",
    "        f0 = x['f0_hz']\n",
    "        harm_amps = x['harmonic_distribution']\n",
    "        loudness = x['amplitudes']\n",
    "        \n",
    "        harmonics, harm_amps = self.prepare_harmonics(f0, harm_amps)\n",
    "        harmonics[:, 0, :] += self.last_phases  # phase offset from last sample\n",
    "        phases = self.generate_phases(harmonics)\n",
    "        self.last_phases[...] = phases[:, -1, :]  # update phase offset\n",
    "        signal = self.generate_signal(harm_amps, loudness, phases)\n",
    "\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = OscillatorBank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_sawtooth_features(fundamental_frequency: float,\n",
    "                             base_amplitude: float,\n",
    "                             n_harmonics: int = 30,\n",
    "                             n_frames: int = 1000,\n",
    "                             batch_size: int = 3) -> Dict[str, torch.Tensor]:\n",
    "    amp = torch.zeros(batch_size, n_frames, 1) + base_amplitude\n",
    "\n",
    "    harmonic_distribution = 1 / torch.arange(1, n_harmonics + 1)\n",
    "    # harmonic_distribution = torch.ones(n_harmonics)  # impulse features\n",
    "    harmonic_distribution = harmonic_distribution[None, None, :].repeat(batch_size, n_frames, 1)\n",
    "\n",
    "    f0_hz = torch.zeros(batch_size, n_frames, 1) + fundamental_frequency\n",
    "\n",
    "    return {\n",
    "        'amplitudes': amp,\n",
    "        'harmonic_distribution': harmonic_distribution,\n",
    "        'f0_hz': f0_hz\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = static_sawtooth_features(220.0, 1.0, 100, 500, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth.cuda()\n",
    "for key, value in params.items():\n",
    "    params[key] = value.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    signal = synth(params)\n",
    "np_signal = signal[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['f0_hz'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_signals = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(500):\n",
    "        signal = synth({k: v[:, idx].unsqueeze(1) for k, v in params.items()})\n",
    "        rt_signals.append(signal)\n",
    "signal = torch.cat(rt_signals, dim=1)\n",
    "np_signal = signal[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np_signal, rate=16000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_to_impulse_response(amp: Tensor, target_size: int) -> Tensor:\n",
    "    amp = torch.stack([amp, torch.zeros_like(amp)], -1)\n",
    "    amp = torch.view_as_complex(amp)\n",
    "    amp = fft.irfft(amp)\n",
    "\n",
    "    filter_size = int(amp.size(-1))\n",
    "\n",
    "    amp = torch.roll(amp, filter_size // 2, -1)\n",
    "    win = torch.hann_window(filter_size, dtype=amp.dtype, device=amp.device)\n",
    "\n",
    "    amp = amp * win\n",
    "\n",
    "    amp = F.pad(amp, (0, int(target_size) - int(filter_size)))\n",
    "    amp = torch.roll(amp, -filter_size // 2, -1)\n",
    "\n",
    "    return amp\n",
    "\n",
    "\n",
    "def fft_convolve(signal: Tensor, kernel: Tensor) -> Tensor:\n",
    "    signal = F.pad(signal, (0, signal.shape[-1]))\n",
    "    kernel = F.pad(kernel, (kernel.shape[-1], 0))\n",
    "\n",
    "    output = fft.irfft(fft.rfft(signal) * fft.rfft(kernel))\n",
    "    output = output[..., output.shape[-1] // 2 :]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class FilteredNoise(nn.Module):\n",
    "    def __init__(self, hop_size=512):\n",
    "        super().__init__()\n",
    "        self.block_size = hop_size\n",
    "\n",
    "    def forward(self, x: Dict[str, Tensor]) -> Tensor:\n",
    "        param = x['noise_bands']\n",
    "\n",
    "        impulse = amp_to_impulse_response(param, self.block_size)\n",
    "        noise = (\n",
    "            torch.rand(\n",
    "                impulse.shape[0],\n",
    "                impulse.shape[1],\n",
    "                self.block_size,\n",
    "            ).to(impulse.device)\n",
    "            * 2\n",
    "            - 1\n",
    "        )\n",
    "\n",
    "        noise = fft_convolve(noise, impulse).contiguous()\n",
    "        noise = noise.reshape(noise.shape[0], -1)\n",
    "\n",
    "        return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3469dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_synth = FilteredNoise(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_params = torch.zeros(4, 20, 16000)\n",
    "noise_params[:, :, 2] = 0.5\n",
    "noise_params[:, :, 22] = 0.5\n",
    "noise_params = dict(noise_bands=noise_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_signal = noise_synth(noise_params)\n",
    "np_noise_signal = noise_signal[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np_noise_signal, rate=16000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_spectrum = np.abs(librosa.stft(np_noise_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6256d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(librosa.amplitude_to_db(noise_spectrum), sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for time_step in noise_params['noise_bands'].permute(1, 0, 2):\n",
    "    time_step = time_step.unsqueeze(1)\n",
    "    results.append(noise_synth({'noise_bands': time_step}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.cat(results, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d242e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_result =result[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np_result, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f16a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_result_spectrum = np.abs(librosa.stft(np_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6151349",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(librosa.amplitude_to_db(np_result_spectrum), sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fft.rfft(result)[0].abs().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95e3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
